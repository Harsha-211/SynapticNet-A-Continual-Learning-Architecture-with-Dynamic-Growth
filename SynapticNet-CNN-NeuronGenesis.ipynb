{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "746660cb-08c5-4a93-bf3e-b8d6d706ff0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())\n",
    "else:\n",
    "    print(\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e7f85fe-3afc-4b33-be00-1b1e43338f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, task_ids, \n",
    "                 stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size if isinstance(kernel_size, tuple) else (kernel_size, kernel_size)\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.groups = groups\n",
    "        self.task_ids = task_ids\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.randn(out_channels, in_channels, *self.kernel_size) * 0.01)\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.randn(out_channels) * 0.01)\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        self.register_buffer(\"channel_task_ids\", torch.tensor(task_ids).long())\n",
    "    \n",
    "    def forward(self, x, task_id):\n",
    "        out = F.conv2d(x, self.weight, self.bias, self.stride, \n",
    "                      self.padding, self.dilation, self.groups)\n",
    "        \n",
    "        mask = (self.channel_task_ids == task_id).float()\n",
    "        self._mask = self.channel_task_ids == task_id\n",
    "        mask = mask.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "        \n",
    "        return out * mask\n",
    "    \n",
    "    def apply_gradient_mask(self):\n",
    "        if self.weight.grad is not None:\n",
    "            inactive = ~self._mask\n",
    "            self.weight.grad[inactive] = 0\n",
    "            if self.bias is not None:\n",
    "                self.bias.grad[inactive] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9410a1f5-d733-408d-a773-e9a611348af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, task_ids):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features \n",
    "        self.out_features = out_features\n",
    "        self.task_ids = task_ids\n",
    "        self.weight = nn.Parameter(torch.randn(out_features, in_features) * 0.01)\n",
    "        self.bias = nn.Parameter(torch.randn(out_features) * 0.01)\n",
    "        self.register_buffer(\"neuron_ids\", torch.tensor(task_ids).long())\n",
    "\n",
    "    def forward(self, x, task_id):\n",
    "        out = F.linear(x, self.weight, self.bias)\n",
    "        mask = (self.neuron_ids == task_id).float().unsqueeze(0)\n",
    "        self._mask = self.neuron_ids == task_id\n",
    "        return out * mask\n",
    "\n",
    "    def apply_gradient_mask(self):\n",
    "        if self.weight.grad is not None:\n",
    "            inactive = ~self._mask\n",
    "            self.weight.grad[inactive] = 0\n",
    "            self.bias.grad[inactive] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a0c484-22c5-4054-9079-3c998e627e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskConvSynapticNet(nn.Module):\n",
    "    def __init__(self, input_channels=3, initial_conv_channels=64, \n",
    "                 hidden_size=512, output_size=10, num_conv_layers=4):\n",
    "        super().__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.conv_channels = initial_conv_channels\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        \n",
    "        # First conv layer (handles different input channels for different datasets)\n",
    "        task_ids = [1] * initial_conv_channels\n",
    "        self.conv_layers.append(\n",
    "            TaskConv2d(input_channels, initial_conv_channels, 3, task_ids, padding=1)\n",
    "        )\n",
    "        \n",
    "        # Additional conv layers\n",
    "        for i in range(1, num_conv_layers):\n",
    "            task_ids = [1] * initial_conv_channels\n",
    "            self.conv_layers.append(\n",
    "                TaskConv2d(initial_conv_channels, initial_conv_channels, 3, task_ids, padding=1)\n",
    "            )\n",
    "        \n",
    "        # MaxPool and dropout\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))  # Ensures consistent output size\n",
    "        \n",
    "        # Calculate flattened size after adaptive pooling\n",
    "        flattened_size = initial_conv_channels * 4 * 4\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = TaskLinear(flattened_size, hidden_size, [1] * hidden_size)\n",
    "        self.fc2 = TaskLinear(hidden_size, output_size, [1] * output_size)\n",
    "        \n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def grow(self, grow_conv_channels=64, grow_hidden=512, grow_output=10, task_id=2):\n",
    "        \"\"\"Grow the network for a new task\"\"\"\n",
    "        new_conv_channels = self.conv_channels + grow_conv_channels\n",
    "        new_hidden_size = self.hidden_size + grow_hidden\n",
    "        new_output_size = self.fc2.out_features + grow_output\n",
    "        \n",
    "        new_conv_task_ids = [task_id] * grow_conv_channels\n",
    "        new_hidden_task_ids = [task_id] * grow_hidden\n",
    "        new_output_task_ids = [task_id] * grow_output\n",
    "        \n",
    "        # Grow convolutional layers\n",
    "        new_conv_layers = nn.ModuleList()\n",
    "        \n",
    "        for i, old_conv in enumerate(self.conv_layers):\n",
    "            old_task_ids = old_conv.task_ids\n",
    "            combined_task_ids = old_task_ids + new_conv_task_ids\n",
    "            \n",
    "            if i == 0:\n",
    "                new_conv = TaskConv2d(\n",
    "                    self.input_channels, new_conv_channels, 3, \n",
    "                    combined_task_ids, padding=1\n",
    "                )\n",
    "            else:\n",
    "                new_conv = TaskConv2d(\n",
    "                    new_conv_channels, new_conv_channels, 3,\n",
    "                    combined_task_ids, padding=1\n",
    "                )\n",
    "            \n",
    "            # Copy old weights\n",
    "            with torch.no_grad():\n",
    "                old_out_channels = old_conv.out_channels\n",
    "                if i == 0:\n",
    "                    new_conv.weight[:old_out_channels].copy_(old_conv.weight)\n",
    "                else:\n",
    "                    new_conv.weight[:old_out_channels, :self.conv_channels].copy_(old_conv.weight)\n",
    "                new_conv.bias[:old_out_channels].copy_(old_conv.bias)\n",
    "            \n",
    "            new_conv_layers.append(new_conv)\n",
    "        \n",
    "        self.conv_layers = new_conv_layers\n",
    "        \n",
    "        # Update flattened size calculation\n",
    "        new_flattened_size = new_conv_channels * 4 * 4\n",
    "        \n",
    "        # Grow FC1 layer\n",
    "        old_fc1_task_ids = self.fc1.task_ids\n",
    "        combined_fc1_task_ids = old_fc1_task_ids + new_hidden_task_ids\n",
    "        \n",
    "        new_fc1 = TaskLinear(new_flattened_size, new_hidden_size, combined_fc1_task_ids)\n",
    "        with torch.no_grad():\n",
    "            old_features = self.fc1.in_features\n",
    "            old_hidden = self.fc1.out_features\n",
    "            new_fc1.weight[:old_hidden, :old_features].copy_(self.fc1.weight)\n",
    "            new_fc1.bias[:old_hidden].copy_(self.fc1.bias)\n",
    "        \n",
    "        self.fc1 = new_fc1\n",
    "        \n",
    "        # Grow FC2 layer\n",
    "        old_fc2_task_ids = self.fc2.task_ids\n",
    "        combined_fc2_task_ids = old_fc2_task_ids + new_output_task_ids\n",
    "        \n",
    "        new_fc2 = TaskLinear(new_hidden_size, new_output_size, combined_fc2_task_ids)\n",
    "        with torch.no_grad():\n",
    "            old_output = self.fc2.out_features\n",
    "            old_hidden = self.fc2.in_features\n",
    "            new_fc2.weight[:old_output, :old_hidden].copy_(self.fc2.weight)\n",
    "            new_fc2.bias[:old_output].copy_(self.fc2.bias)\n",
    "        \n",
    "        self.fc2 = new_fc2\n",
    "        \n",
    "        # Update dimensions\n",
    "        self.conv_channels = new_conv_channels\n",
    "        self.hidden_size = new_hidden_size\n",
    "    \n",
    "    def forward(self, x, task_id):\n",
    "        # Convolutional layers with pooling\n",
    "        for i, conv_layer in enumerate(self.conv_layers):\n",
    "            x = self.relu(conv_layer(x, task_id))\n",
    "            if i < len(self.conv_layers) - 1:  # Don't pool after last conv layer\n",
    "                x = self.pool(x)\n",
    "        \n",
    "        # Adaptive pooling to handle different input sizes\n",
    "        x = self.adaptive_pool(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.dropout(self.relu(self.fc1(x, task_id)))\n",
    "        x = self.fc2(x, task_id)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def apply_task_gradient_mask(self):\n",
    "        for conv_layer in self.conv_layers:\n",
    "            conv_layer.apply_gradient_mask()\n",
    "        self.fc1.apply_gradient_mask()\n",
    "        self.fc2.apply_gradient_mask()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c405cc8e-8632-478a-9bec-58b2d7289d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, dataset, task_id, label_offset=0, input_size=(32, 32)):\n",
    "        self.dataset = dataset\n",
    "        self.task_id = task_id\n",
    "        self.label_offset = label_offset\n",
    "        self.input_size = input_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.dataset[idx]\n",
    "        \n",
    "        # Handle different input sizes (MNIST vs CIFAR)\n",
    "        if x.shape[1:] != self.input_size:\n",
    "            # Resize if needed (for MNIST -> 32x32)\n",
    "            resize_transform = transforms.Resize(self.input_size)\n",
    "            x = resize_transform(x)\n",
    "        \n",
    "        # Handle grayscale vs RGB (MNIST vs CIFAR)\n",
    "        if x.shape[0] == 1 and self.input_size == (32, 32):\n",
    "            # Convert grayscale to RGB for consistency\n",
    "            x = x.repeat(3, 1, 1)\n",
    "        \n",
    "        return x, y + self.label_offset, self.task_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43756806-b7f6-4cb8-b457-7d1e255a2811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_dataloaders(batch_size=64):\n",
    "    # Different transforms for grayscale vs color datasets\n",
    "    transform_gray = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    transform_color = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    # Load datasets\n",
    "    mnist = datasets.MNIST(root='./data', train=True, download=True, transform=transform_gray)\n",
    "    fmnist = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform_gray)\n",
    "    cifar10 = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_color)\n",
    "    cifar100 = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_color)\n",
    "\n",
    "    # Create task datasets with appropriate label offsets\n",
    "    mnist_task = TaskDataset(mnist, task_id=1, label_offset=0, input_size=(32, 32))\n",
    "    fmnist_task = TaskDataset(fmnist, task_id=2, label_offset=10, input_size=(32, 32))\n",
    "    cifar10_task = TaskDataset(cifar10, task_id=3, label_offset=20, input_size=(32, 32))\n",
    "    cifar100_task = TaskDataset(cifar100, task_id=4, label_offset=30, input_size=(32, 32))\n",
    "\n",
    "    # Create data loaders\n",
    "    mnist_loader = DataLoader(mnist_task, batch_size=batch_size, shuffle=True)\n",
    "    fmnist_loader = DataLoader(fmnist_task, batch_size=batch_size, shuffle=True)\n",
    "    cifar10_loader = DataLoader(cifar10_task, batch_size=batch_size, shuffle=True)\n",
    "    cifar100_loader = DataLoader(cifar100_task, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return mnist_loader, fmnist_loader, cifar10_loader, cifar100_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8525e008-dc14-45a5-b080-017a38427325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_task(model, task_id, dataloader, epochs=5, lr=1e-3):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (x, y, tid) in enumerate(dataloader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model(x, task_id)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            \n",
    "            model.apply_task_gradient_mask()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(out, dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            \n",
    "            # Print progress every 200 batches\n",
    "            if batch_idx % 200 == 0:\n",
    "                batch_acc = 100 * (preds == y).sum().item() / y.size(0)\n",
    "                print(f\"[Task {task_id}] Epoch {epoch+1}, Batch {batch_idx} | Loss: {loss.item():.4f} | Batch Acc: {batch_acc:.2f}%\")\n",
    "        \n",
    "        acc = 100 * correct / total\n",
    "        print(f\"[Task {task_id}] Epoch {epoch+1} | Loss: {total_loss:.4f} | Accuracy: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6b052b3-becd-4a58-8115-02f6fa1f7597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_task(model, task_id, dataloader, task_name=\"\"):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y, tid in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x, task_id)\n",
    "            preds = torch.argmax(out, dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"[Task {task_id}] {task_name} Evaluation Accuracy: {acc:.2f}%\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4c376b2-528a-4cf0-b247-83d239d28933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a85212e-0892-40b6-b4d2-b132112b2d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiTaskConvSynapticNet(\n",
    "        input_channels=3,  # RGB for all datasets (MNIST will be converted)\n",
    "        initial_conv_channels=64, \n",
    "        hidden_size=512, \n",
    "        output_size=10,  # Start with 10 classes for MNIST\n",
    "        num_conv_layers=4\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfd98401-e823-44c0-82c0-0d6ceb7a3ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all data loaders\n",
    "mnist_loader, fmnist_loader, cifar10_loader, cifar100_loader = get_all_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e2de616-2977-407b-b94a-44de2a7fc3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training on MNIST (Task 1)\n",
      "==================================================\n",
      "[Task 1] Epoch 1, Batch 0 | Loss: 2.3016 | Batch Acc: 15.62%\n",
      "[Task 1] Epoch 1, Batch 200 | Loss: 0.3233 | Batch Acc: 89.06%\n",
      "[Task 1] Epoch 1, Batch 400 | Loss: 0.1036 | Batch Acc: 96.88%\n",
      "[Task 1] Epoch 1, Batch 600 | Loss: 0.0399 | Batch Acc: 98.44%\n",
      "[Task 1] Epoch 1, Batch 800 | Loss: 0.1133 | Batch Acc: 93.75%\n",
      "[Task 1] Epoch 1 | Loss: 262.2521 | Accuracy: 90.34%\n",
      "[Task 1] Epoch 2, Batch 0 | Loss: 0.0543 | Batch Acc: 96.88%\n",
      "[Task 1] Epoch 2, Batch 200 | Loss: 0.0943 | Batch Acc: 98.44%\n",
      "[Task 1] Epoch 2, Batch 400 | Loss: 0.0244 | Batch Acc: 100.00%\n",
      "[Task 1] Epoch 2, Batch 600 | Loss: 0.0215 | Batch Acc: 100.00%\n",
      "[Task 1] Epoch 2, Batch 800 | Loss: 0.0235 | Batch Acc: 100.00%\n",
      "[Task 1] Epoch 2 | Loss: 54.3520 | Accuracy: 98.24%\n",
      "[Task 1] Epoch 3, Batch 0 | Loss: 0.0165 | Batch Acc: 100.00%\n",
      "[Task 1] Epoch 3, Batch 200 | Loss: 0.0178 | Batch Acc: 100.00%\n",
      "[Task 1] Epoch 3, Batch 400 | Loss: 0.0275 | Batch Acc: 98.44%\n",
      "[Task 1] Epoch 3, Batch 600 | Loss: 0.0576 | Batch Acc: 96.88%\n",
      "[Task 1] Epoch 3, Batch 800 | Loss: 0.0620 | Batch Acc: 96.88%\n",
      "[Task 1] Epoch 3 | Loss: 40.7235 | Accuracy: 98.67%\n"
     ]
    }
   ],
   "source": [
    "# Task 1: MNIST\n",
    "print(\"=\" * 50)\n",
    "print(\"Training on MNIST (Task 1)\")\n",
    "print(\"=\" * 50)\n",
    "train_task(model, task_id=1, dataloader=mnist_loader, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "456c992f-d044-4a30-81b9-bae2472017b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Growing network for Fashion-MNIST (Task 2)...\n"
     ]
    }
   ],
   "source": [
    "# Grow for Task 2: Fashion-MNIST\n",
    "print(\"\\nGrowing network for Fashion-MNIST (Task 2)...\")\n",
    "model.grow(grow_conv_channels=64, grow_hidden=512, grow_output=10, task_id=2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84f16d7b-b38e-4d6a-b59c-6e91c259832d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training on Fashion-MNIST (Task 2)\n",
      "==================================================\n",
      "[Task 2] Epoch 1, Batch 0 | Loss: 0.3362 | Batch Acc: 82.81%\n",
      "[Task 2] Epoch 1, Batch 200 | Loss: 0.3196 | Batch Acc: 84.38%\n",
      "[Task 2] Epoch 1, Batch 400 | Loss: 0.2849 | Batch Acc: 90.62%\n",
      "[Task 2] Epoch 1, Batch 600 | Loss: 0.3722 | Batch Acc: 89.06%\n",
      "[Task 2] Epoch 1, Batch 800 | Loss: 0.4145 | Batch Acc: 85.94%\n",
      "[Task 2] Epoch 1 | Loss: 274.1069 | Accuracy: 89.24%\n",
      "[Task 2] Epoch 2, Batch 0 | Loss: 0.3152 | Batch Acc: 89.06%\n",
      "[Task 2] Epoch 2, Batch 200 | Loss: 0.2286 | Batch Acc: 90.62%\n",
      "[Task 2] Epoch 2, Batch 400 | Loss: 0.3027 | Batch Acc: 85.94%\n",
      "[Task 2] Epoch 2, Batch 600 | Loss: 0.1682 | Batch Acc: 93.75%\n",
      "[Task 2] Epoch 2, Batch 800 | Loss: 0.2939 | Batch Acc: 85.94%\n",
      "[Task 2] Epoch 2 | Loss: 245.1158 | Accuracy: 90.38%\n",
      "[Task 2] Epoch 3, Batch 0 | Loss: 0.2448 | Batch Acc: 87.50%\n",
      "[Task 2] Epoch 3, Batch 200 | Loss: 0.1968 | Batch Acc: 92.19%\n",
      "[Task 2] Epoch 3, Batch 400 | Loss: 0.2354 | Batch Acc: 92.19%\n",
      "[Task 2] Epoch 3, Batch 600 | Loss: 0.1724 | Batch Acc: 93.75%\n",
      "[Task 2] Epoch 3, Batch 800 | Loss: 0.2392 | Batch Acc: 90.62%\n",
      "[Task 2] Epoch 3 | Loss: 225.1052 | Accuracy: 91.18%\n",
      "[Task 2] Epoch 4, Batch 0 | Loss: 0.2276 | Batch Acc: 89.06%\n",
      "[Task 2] Epoch 4, Batch 200 | Loss: 0.1585 | Batch Acc: 92.19%\n",
      "[Task 2] Epoch 4, Batch 400 | Loss: 0.2122 | Batch Acc: 92.19%\n",
      "[Task 2] Epoch 4, Batch 600 | Loss: 0.3382 | Batch Acc: 90.62%\n",
      "[Task 2] Epoch 4, Batch 800 | Loss: 0.2423 | Batch Acc: 89.06%\n",
      "[Task 2] Epoch 4 | Loss: 206.9753 | Accuracy: 91.82%\n",
      "[Task 2] Epoch 5, Batch 0 | Loss: 0.1132 | Batch Acc: 95.31%\n",
      "[Task 2] Epoch 5, Batch 200 | Loss: 0.2361 | Batch Acc: 93.75%\n",
      "[Task 2] Epoch 5, Batch 400 | Loss: 0.1744 | Batch Acc: 95.31%\n",
      "[Task 2] Epoch 5, Batch 600 | Loss: 0.3197 | Batch Acc: 84.38%\n",
      "[Task 2] Epoch 5, Batch 800 | Loss: 0.2359 | Batch Acc: 92.19%\n",
      "[Task 2] Epoch 5 | Loss: 192.5550 | Accuracy: 92.36%\n",
      "[Task 2] Epoch 6, Batch 0 | Loss: 0.3276 | Batch Acc: 92.19%\n",
      "[Task 2] Epoch 6, Batch 200 | Loss: 0.1401 | Batch Acc: 95.31%\n",
      "[Task 2] Epoch 6, Batch 400 | Loss: 0.1162 | Batch Acc: 95.31%\n",
      "[Task 2] Epoch 6, Batch 600 | Loss: 0.1444 | Batch Acc: 93.75%\n",
      "[Task 2] Epoch 6, Batch 800 | Loss: 0.1247 | Batch Acc: 93.75%\n",
      "[Task 2] Epoch 6 | Loss: 178.8497 | Accuracy: 92.90%\n",
      "[Task 2] Epoch 7, Batch 0 | Loss: 0.1496 | Batch Acc: 96.88%\n",
      "[Task 2] Epoch 7, Batch 200 | Loss: 0.2660 | Batch Acc: 90.62%\n",
      "[Task 2] Epoch 7, Batch 400 | Loss: 0.2860 | Batch Acc: 90.62%\n",
      "[Task 2] Epoch 7, Batch 600 | Loss: 0.2728 | Batch Acc: 92.19%\n",
      "[Task 2] Epoch 7, Batch 800 | Loss: 0.2043 | Batch Acc: 89.06%\n",
      "[Task 2] Epoch 7 | Loss: 169.6018 | Accuracy: 93.27%\n",
      "[Task 2] Epoch 8, Batch 0 | Loss: 0.2499 | Batch Acc: 93.75%\n",
      "[Task 2] Epoch 8, Batch 200 | Loss: 0.0681 | Batch Acc: 96.88%\n",
      "[Task 2] Epoch 8, Batch 400 | Loss: 0.3801 | Batch Acc: 89.06%\n",
      "[Task 2] Epoch 8, Batch 600 | Loss: 0.3437 | Batch Acc: 89.06%\n",
      "[Task 2] Epoch 8, Batch 800 | Loss: 0.1599 | Batch Acc: 95.31%\n",
      "[Task 2] Epoch 8 | Loss: 154.3738 | Accuracy: 93.81%\n",
      "[Task 2] Epoch 9, Batch 0 | Loss: 0.1538 | Batch Acc: 93.75%\n",
      "[Task 2] Epoch 9, Batch 200 | Loss: 0.2183 | Batch Acc: 92.19%\n",
      "[Task 2] Epoch 9, Batch 400 | Loss: 0.1513 | Batch Acc: 96.88%\n",
      "[Task 2] Epoch 9, Batch 600 | Loss: 0.1593 | Batch Acc: 92.19%\n",
      "[Task 2] Epoch 9, Batch 800 | Loss: 0.2325 | Batch Acc: 89.06%\n",
      "[Task 2] Epoch 9 | Loss: 146.4872 | Accuracy: 94.12%\n",
      "[Task 2] Epoch 10, Batch 0 | Loss: 0.1771 | Batch Acc: 92.19%\n",
      "[Task 2] Epoch 10, Batch 200 | Loss: 0.2817 | Batch Acc: 93.75%\n",
      "[Task 2] Epoch 10, Batch 400 | Loss: 0.1477 | Batch Acc: 96.88%\n",
      "[Task 2] Epoch 10, Batch 600 | Loss: 0.1063 | Batch Acc: 93.75%\n",
      "[Task 2] Epoch 10, Batch 800 | Loss: 0.2752 | Batch Acc: 92.19%\n",
      "[Task 2] Epoch 10 | Loss: 135.3602 | Accuracy: 94.54%\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"Training on Fashion-MNIST (Task 2)\")\n",
    "print(\"=\" * 50)\n",
    "train_task(model, task_id=2, dataloader=fmnist_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "912cf1f0-98b7-4c4b-89f2-07abd6a45cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Growing network for CIFAR-10 (Task 3)...\n"
     ]
    }
   ],
   "source": [
    "# Grow for Task 3: CIFAR-10\n",
    "print(\"\\nGrowing network for CIFAR-10 (Task 3)...\")\n",
    "model.grow(grow_conv_channels=64, grow_hidden=512, grow_output=10, task_id=3)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "377366ec-fdf6-44a0-be9c-ab7ad6115105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training on CIFAR-10 (Task 3)\n",
      "==================================================\n",
      "[Task 3] Epoch 1, Batch 0 | Loss: 0.2766 | Batch Acc: 90.62%\n",
      "[Task 3] Epoch 1, Batch 200 | Loss: 0.5149 | Batch Acc: 85.94%\n",
      "[Task 3] Epoch 1, Batch 400 | Loss: 0.2926 | Batch Acc: 93.75%\n",
      "[Task 3] Epoch 1, Batch 600 | Loss: 0.4333 | Batch Acc: 82.81%\n",
      "[Task 3] Epoch 1 | Loss: 377.0778 | Accuracy: 82.99%\n",
      "[Task 3] Epoch 2, Batch 0 | Loss: 0.4307 | Batch Acc: 79.69%\n",
      "[Task 3] Epoch 2, Batch 200 | Loss: 0.5021 | Batch Acc: 85.94%\n",
      "[Task 3] Epoch 2, Batch 400 | Loss: 0.5158 | Batch Acc: 84.38%\n",
      "[Task 3] Epoch 2, Batch 600 | Loss: 0.5037 | Batch Acc: 78.12%\n",
      "[Task 3] Epoch 2 | Loss: 344.2313 | Accuracy: 84.42%\n",
      "[Task 3] Epoch 3, Batch 0 | Loss: 0.2526 | Batch Acc: 89.06%\n",
      "[Task 3] Epoch 3, Batch 200 | Loss: 0.6546 | Batch Acc: 79.69%\n",
      "[Task 3] Epoch 3, Batch 400 | Loss: 0.3946 | Batch Acc: 87.50%\n",
      "[Task 3] Epoch 3, Batch 600 | Loss: 0.2156 | Batch Acc: 93.75%\n",
      "[Task 3] Epoch 3 | Loss: 321.6060 | Accuracy: 85.40%\n",
      "[Task 3] Epoch 4, Batch 0 | Loss: 0.3311 | Batch Acc: 85.94%\n",
      "[Task 3] Epoch 4, Batch 200 | Loss: 0.4754 | Batch Acc: 84.38%\n",
      "[Task 3] Epoch 4, Batch 400 | Loss: 0.5009 | Batch Acc: 78.12%\n",
      "[Task 3] Epoch 4, Batch 600 | Loss: 0.2821 | Batch Acc: 87.50%\n",
      "[Task 3] Epoch 4 | Loss: 297.7318 | Accuracy: 86.33%\n",
      "[Task 3] Epoch 5, Batch 0 | Loss: 0.3023 | Batch Acc: 92.19%\n",
      "[Task 3] Epoch 5, Batch 200 | Loss: 0.2982 | Batch Acc: 89.06%\n",
      "[Task 3] Epoch 5, Batch 400 | Loss: 0.2924 | Batch Acc: 87.50%\n",
      "[Task 3] Epoch 5, Batch 600 | Loss: 0.3327 | Batch Acc: 85.94%\n",
      "[Task 3] Epoch 5 | Loss: 273.2172 | Accuracy: 87.47%\n",
      "[Task 3] Epoch 6, Batch 0 | Loss: 0.3747 | Batch Acc: 89.06%\n",
      "[Task 3] Epoch 6, Batch 200 | Loss: 0.2674 | Batch Acc: 90.62%\n",
      "[Task 3] Epoch 6, Batch 400 | Loss: 0.3824 | Batch Acc: 89.06%\n",
      "[Task 3] Epoch 6, Batch 600 | Loss: 0.3204 | Batch Acc: 84.38%\n",
      "[Task 3] Epoch 6 | Loss: 258.7195 | Accuracy: 88.07%\n",
      "[Task 3] Epoch 7, Batch 0 | Loss: 0.2304 | Batch Acc: 92.19%\n",
      "[Task 3] Epoch 7, Batch 200 | Loss: 0.2326 | Batch Acc: 92.19%\n",
      "[Task 3] Epoch 7, Batch 400 | Loss: 0.2679 | Batch Acc: 92.19%\n",
      "[Task 3] Epoch 7, Batch 600 | Loss: 0.4000 | Batch Acc: 89.06%\n",
      "[Task 3] Epoch 7 | Loss: 235.6030 | Accuracy: 88.95%\n",
      "[Task 3] Epoch 8, Batch 0 | Loss: 0.2264 | Batch Acc: 93.75%\n",
      "[Task 3] Epoch 8, Batch 200 | Loss: 0.3250 | Batch Acc: 87.50%\n",
      "[Task 3] Epoch 8, Batch 400 | Loss: 0.6290 | Batch Acc: 81.25%\n",
      "[Task 3] Epoch 8, Batch 600 | Loss: 0.3702 | Batch Acc: 89.06%\n",
      "[Task 3] Epoch 8 | Loss: 219.5775 | Accuracy: 89.81%\n",
      "[Task 3] Epoch 9, Batch 0 | Loss: 0.3013 | Batch Acc: 85.94%\n",
      "[Task 3] Epoch 9, Batch 200 | Loss: 0.1737 | Batch Acc: 93.75%\n",
      "[Task 3] Epoch 9, Batch 400 | Loss: 0.2391 | Batch Acc: 89.06%\n",
      "[Task 3] Epoch 9, Batch 600 | Loss: 0.1918 | Batch Acc: 92.19%\n",
      "[Task 3] Epoch 9 | Loss: 205.8180 | Accuracy: 90.35%\n",
      "[Task 3] Epoch 10, Batch 0 | Loss: 0.2695 | Batch Acc: 87.50%\n",
      "[Task 3] Epoch 10, Batch 200 | Loss: 0.1800 | Batch Acc: 93.75%\n",
      "[Task 3] Epoch 10, Batch 400 | Loss: 0.1203 | Batch Acc: 98.44%\n",
      "[Task 3] Epoch 10, Batch 600 | Loss: 0.2048 | Batch Acc: 90.62%\n",
      "[Task 3] Epoch 10 | Loss: 193.5225 | Accuracy: 90.97%\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"Training on CIFAR-10 (Task 3)\")\n",
    "print(\"=\" * 50)\n",
    "train_task(model, task_id=3, dataloader=cifar10_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2efefa0-7453-4401-b87f-be4f60a5aa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Growing network for CIFAR-100 (Task 4)...\n"
     ]
    }
   ],
   "source": [
    "# Grow for Task 4: CIFAR-100\n",
    "print(\"\\nGrowing network for CIFAR-100 (Task 4)...\")\n",
    "model.grow(grow_conv_channels=128, grow_hidden=1024, grow_output=100, task_id=4)  # Larger growth for 100 classes\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ff4ecd5-23ab-40ed-b296-349d86e128e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training on CIFAR-100 (Task 4)\n",
      "==================================================\n",
      "[Task 4] Epoch 1, Batch 0 | Loss: 0.5195 | Batch Acc: 84.38%\n",
      "[Task 4] Epoch 1, Batch 200 | Loss: 0.7242 | Batch Acc: 73.44%\n",
      "[Task 4] Epoch 1, Batch 400 | Loss: 0.6208 | Batch Acc: 84.38%\n",
      "[Task 4] Epoch 1, Batch 600 | Loss: 0.9654 | Batch Acc: 67.19%\n",
      "[Task 4] Epoch 1 | Loss: 666.2282 | Accuracy: 73.52%\n",
      "[Task 4] Epoch 2, Batch 0 | Loss: 0.7491 | Batch Acc: 70.31%\n",
      "[Task 4] Epoch 2, Batch 200 | Loss: 0.9515 | Batch Acc: 73.44%\n",
      "[Task 4] Epoch 2, Batch 400 | Loss: 0.7985 | Batch Acc: 75.00%\n",
      "[Task 4] Epoch 2, Batch 600 | Loss: 0.9242 | Batch Acc: 71.88%\n",
      "[Task 4] Epoch 2 | Loss: 613.4397 | Accuracy: 75.30%\n",
      "[Task 4] Epoch 3, Batch 0 | Loss: 0.6444 | Batch Acc: 79.69%\n",
      "[Task 4] Epoch 3, Batch 200 | Loss: 0.6371 | Batch Acc: 81.25%\n",
      "[Task 4] Epoch 3, Batch 400 | Loss: 0.8191 | Batch Acc: 71.88%\n",
      "[Task 4] Epoch 3, Batch 600 | Loss: 0.7537 | Batch Acc: 75.00%\n",
      "[Task 4] Epoch 3 | Loss: 591.1565 | Accuracy: 76.12%\n",
      "[Task 4] Epoch 4, Batch 0 | Loss: 0.5244 | Batch Acc: 84.38%\n",
      "[Task 4] Epoch 4, Batch 200 | Loss: 0.6127 | Batch Acc: 78.12%\n",
      "[Task 4] Epoch 4, Batch 400 | Loss: 0.7827 | Batch Acc: 79.69%\n",
      "[Task 4] Epoch 4, Batch 600 | Loss: 0.6438 | Batch Acc: 75.00%\n",
      "[Task 4] Epoch 4 | Loss: 558.1647 | Accuracy: 77.58%\n",
      "[Task 4] Epoch 5, Batch 0 | Loss: 0.2214 | Batch Acc: 96.88%\n",
      "[Task 4] Epoch 5, Batch 200 | Loss: 1.0428 | Batch Acc: 67.19%\n",
      "[Task 4] Epoch 5, Batch 400 | Loss: 0.9922 | Batch Acc: 75.00%\n",
      "[Task 4] Epoch 5, Batch 600 | Loss: 0.6788 | Batch Acc: 82.81%\n",
      "[Task 4] Epoch 5 | Loss: 539.0623 | Accuracy: 78.14%\n",
      "[Task 4] Epoch 6, Batch 0 | Loss: 0.6932 | Batch Acc: 71.88%\n",
      "[Task 4] Epoch 6, Batch 200 | Loss: 0.6029 | Batch Acc: 85.94%\n",
      "[Task 4] Epoch 6, Batch 400 | Loss: 0.9403 | Batch Acc: 73.44%\n",
      "[Task 4] Epoch 6, Batch 600 | Loss: 0.9154 | Batch Acc: 75.00%\n",
      "[Task 4] Epoch 6 | Loss: 520.8671 | Accuracy: 78.80%\n",
      "[Task 4] Epoch 7, Batch 0 | Loss: 0.6309 | Batch Acc: 75.00%\n",
      "[Task 4] Epoch 7, Batch 200 | Loss: 0.4780 | Batch Acc: 81.25%\n",
      "[Task 4] Epoch 7, Batch 400 | Loss: 0.8110 | Batch Acc: 81.25%\n",
      "[Task 4] Epoch 7, Batch 600 | Loss: 0.8362 | Batch Acc: 73.44%\n",
      "[Task 4] Epoch 7 | Loss: 494.0883 | Accuracy: 79.65%\n",
      "[Task 4] Epoch 8, Batch 0 | Loss: 0.3895 | Batch Acc: 84.38%\n",
      "[Task 4] Epoch 8, Batch 200 | Loss: 0.7154 | Batch Acc: 81.25%\n",
      "[Task 4] Epoch 8, Batch 400 | Loss: 0.5773 | Batch Acc: 79.69%\n",
      "[Task 4] Epoch 8, Batch 600 | Loss: 0.4906 | Batch Acc: 85.94%\n",
      "[Task 4] Epoch 8 | Loss: 470.4707 | Accuracy: 80.68%\n",
      "[Task 4] Epoch 9, Batch 0 | Loss: 0.6772 | Batch Acc: 81.25%\n",
      "[Task 4] Epoch 9, Batch 200 | Loss: 0.4720 | Batch Acc: 82.81%\n",
      "[Task 4] Epoch 9, Batch 400 | Loss: 0.5460 | Batch Acc: 82.81%\n",
      "[Task 4] Epoch 9, Batch 600 | Loss: 0.6973 | Batch Acc: 79.69%\n",
      "[Task 4] Epoch 9 | Loss: 460.5208 | Accuracy: 81.07%\n",
      "[Task 4] Epoch 10, Batch 0 | Loss: 0.4885 | Batch Acc: 85.94%\n",
      "[Task 4] Epoch 10, Batch 200 | Loss: 0.4483 | Batch Acc: 84.38%\n",
      "[Task 4] Epoch 10, Batch 400 | Loss: 0.6064 | Batch Acc: 79.69%\n",
      "[Task 4] Epoch 10, Batch 600 | Loss: 0.7985 | Batch Acc: 78.12%\n",
      "[Task 4] Epoch 10 | Loss: 445.7538 | Accuracy: 81.81%\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"Training on CIFAR-100 (Task 4)\")\n",
    "print(\"=\" * 50)\n",
    "train_task(model, task_id=4, dataloader=cifar100_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a0ad379-b6cf-4db6-9053-23e3e7f923f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FINAL EVALUATION ON ALL TASKS\n",
      "==================================================\n",
      "[Task 1] MNIST Evaluation Accuracy: 98.89%\n",
      "[Task 2] Fashion-MNIST Evaluation Accuracy: 95.62%\n",
      "[Task 3] CIFAR-10 Evaluation Accuracy: 93.62%\n",
      "[Task 4] CIFAR-100 Evaluation Accuracy: 93.89%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93.888"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate all tasks\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL EVALUATION ON ALL TASKS\")\n",
    "print(\"=\" * 50)\n",
    "    \n",
    "evaluate_task(model, task_id=1, dataloader=mnist_loader, task_name=\"MNIST\")\n",
    "evaluate_task(model, task_id=2, dataloader=fmnist_loader, task_name=\"Fashion-MNIST\")\n",
    "evaluate_task(model, task_id=3, dataloader=cifar10_loader, task_name=\"CIFAR-10\")\n",
    "evaluate_task(model, task_id=4, dataloader=cifar100_loader, task_name=\"CIFAR-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd12466a-ae6b-49a3-80a9-d81cba0cf381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final network parameters: 16,217,410\n",
      "Final conv channels: 320\n",
      "Final hidden size: 2560\n",
      "Final output size: 130\n"
     ]
    }
   ],
   "source": [
    "# Print final network size\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nFinal network parameters: {total_params:,}\")\n",
    "print(f\"Final conv channels: {model.conv_channels}\")\n",
    "print(f\"Final hidden size: {model.hidden_size}\")\n",
    "print(f\"Final output size: {model.fc2.out_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350aacfc-dd89-411c-a5f4-a53cdcc7eced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
